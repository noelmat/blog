{
  
    
        "post0": {
            "title": "Writing Pytorch DataLoaders",
            "content": "I have often had times when I&#39;d look at problems on kaggle and wonder how would I get this data into a model for training. I now know the answer to this but I was struggling to get it right for quite some time. This blog is for all those who are currently struggling with writing Pytorch Data Loaders. . When it comes to training a Deep Learning model, the first step we need to get right is the writing a DataLoader. The most important thing to consider when writing a dataloader is the Data itself. . Understanding how the data is laid out is vital to writing dataloaders. Quoting from fastai&#39;s book, data is most commonly stored and served in the following two formats: . Individual files representing items of data, such as text documents or images, possibly organized into folders or with filenames representing information about those items | A table of data, such as in CSV format, where each row is an item which may include filenames providing a connection between the data in the table and data in other formats, such as text documents and images | . Lets consider we have our data arranged in the most common format: . a labels.csv | images arranged in separate train and test folders | . We will start by reading a single image file first . 1. Reading the data . We need to get hold of a library that helps us read the data. PIL is commonly used for images, pandas for tabular data. You could easily find those with a simple google search. . We will be using PIL for the image and pandas for reading our labels.csv . import torch import numpy as np import pandas as pd from pathlib import Path Path.ls = lambda x: list(x.iterdir()) from torch import nn from PIL import Image from torchvision import transforms . path = Path(&#39;/kaggle/input/lego-minifigures-classification/&#39;) path.ls() . [PosixPath(&#39;/kaggle/input/lego-minifigures-classification/harry-potter&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/jurassic-world&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/metadata.csv&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/LICENSE&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/marvel&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/index.csv&#39;), PosixPath(&#39;/kaggle/input/lego-minifigures-classification/star-wars&#39;)] . df = pd.read_csv(path/&#39;index.csv&#39;,index_col=0) meta = pd.read_csv(path/&#39;metadata.csv&#39;,index_col=0) df = pd.merge(df,meta, on=&#39;class_id&#39;) . row = df.iloc[0] print(row.minifigure_name) Image.open(path/row.path).resize((128,128)) . SPIDER-MAN . 2. Creating a Dataset . Now that we have successfully read and displayed our image with the label, we can move ahead to writing DataLoaders. Before creating the Dataloader, we need to be able to create a function or an object that does the following things: . store the required metadata for getting the data take an index and return the corresponding image and the target. return the length of the total dataset. In Pytorch, we refer to this as a Dataset. A Dataset is a class that stores the necessary metadata of our data like the data path and the labels DataFrame, and does all the things we have listed before. . class LegoDataset: def __init__(self, path, df, size): self.path = path self.df = df self.size = size self.tfms = transforms.Compose([ transforms.Resize(self.size), transforms.ToTensor() ]) def __len__(self): return len(self.df) def __getitem__(self, idx): row = self.df.iloc[idx] # get the image path img_path = path/row.path # read the image img = Image.open(img_path).convert(&#39;RGB&#39;) # apply the transforms img = self.tfms(img) # read the target target = torch.tensor(row.class_id).long() # return the image with the target return img, target . What we see above is all it takes to write a Dataset class. We can test if we can just pass in a idx and get the image and target as we expect. . dataset = LegoDataset(path, df, size=224) dataset[0][0].shape, dataset[0][1] . (torch.Size([3, 224, 224]), tensor(1)) . We can see that the dataset return a image of size 244 x 244 and 3 channels as we specified while instantiating the dataset object. . 3. Creating a DataLoader . Pytorch gives us a DataLoader class that takes in a dataset, batch size and some other functions and returns a dataloader. Lets understand how to create one. . dl = torch.utils.data.DataLoader( dataset, batch_size=64, shuffle=True ) . x, y = next(iter(dl)) x.shape, y.shape . (torch.Size([64, 3, 224, 224]), torch.Size([64])) . Viola! We have our dataloader ready and we are able to access data by using it as an iterator. Lets start training ;) . Summary: . Remember. There&#39;s 3 steps involved: . Read a single data object and the label | Write a Dataset class which takes an index and returns the data and the label | Use pytorch&#39;s DataLoader class to create a dataloader and we are good to go. |",
            "url": "https://noelmat.github.io/blog/jupyter/2020/09/24/Writing-Pytorch-DataLoaders.html",
            "relUrl": "/jupyter/2020/09/24/Writing-Pytorch-DataLoaders.html",
            "date": " • Sep 24, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://noelmat.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://noelmat.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}